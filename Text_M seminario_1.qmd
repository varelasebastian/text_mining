---
title: "Código de seminario TextM 2025"
---

Se requieren los paquetes openalexR y tidyverse. Instalar con cuadros de diálogo y no con código.

```{r, message=FALSE, warning=FALSE}
library(openalexR)
library(tidyverse)
library(DataExplorer)
```

Explicar brevemente que es un base de datos bibiográfica y qué es Openalex y su comparación con tras bases de datos.

## Seleccionar lo que interesa

Utilizaremos como término de búsqueda las versiones correspondientes a los idiomas español, inglés, italiano, francés, portugues y alemán.

Explicar la busqueda:

```{r}
socio_ar <- oa_fetch(entity = "works",title.search = "sociologia OR sociology OR sociologie OR soziologie OR social",authorships.countries = "AR")
```

Visualizar las 39 variables que hay en el dataset:
```{r}
names(socio_ar)
```

seleccionar las que interesan
```{r}
socio_ar_selec <- socio_ar %>% select(id,title,ab,topics,publication_year)
```

### Análisis de valores perdidos

```{r}
socio_ar_selec %>%
  summarise(across(everything(), ~ mean(is.na(.)), .names = "prop_na_{col}"))
```

```{r, fig.width=5}
plot_missing(socio_ar_selec) #paquete DataExplorer
```

### Ver que artículos son
```{r}
socio_ar_selec %>%
  filter(if_any(everything(), is.na))
```

## Preprocessing

Primer paso del preprocesamiento: tokenización de los **títulos**:
```{r}
library(tidytext) #Instalar antes el paquete tidytext con desde cuadros de diálogo

palab_tit <- socio_ar_selec[, c("id","title")] %>%
  unnest_tokens(palabra,title)
```

Tokenización de los **resumenes**:
```{r}
palab_res <- socio_ar_selec[, c("id","ab")] %>%
  unnest_tokens(palabra,ab)
```

Unir los objetos de datos título y resumen
```{r}
palab_tit_res <- bind_rows(palab_tit, palab_res)
```

### Eliminación de palabras no significativas (stopwords)
```{r}
library(stopwords) #Instalar el paquete stopwords desde cuadros de diálogo
```

Antes vamos a obtener las stopwords ya elaboradas para diferentes idiomas:

```{r}
stopwords_es <- tibble(palabra = stopwords::stopwords("es"))
stopwords_en <- tibble(palabra = stopwords::stopwords("en"))
stopwords_it <- tibble(palabra = stopwords::stopwords("it"))
stopwords_fr <- tibble(palabra = stopwords::stopwords("fr"))
stopwords_pt <- tibble(palabra = stopwords::stopwords("pt"))
stopwords_de <- tibble(palabra = stopwords::stopwords("de"))
```

Eliminar palabras no significativas (stopwods) de la variable título y de título y resumen integrado

```{r}
palab_tit_limp <- palab_tit %>%
  anti_join(stopwords_es, by = "palabra") %>%
  anti_join(stopwords_en, by = "palabra") %>%
  anti_join(stopwords_fr, by = "palabra") %>%
  anti_join(stopwords_it, by = "palabra") %>%
  anti_join(stopwords_pt, by = "palabra") %>%
  anti_join(stopwords_de, by = "palabra")
```

```{r}
palab_tit_res_limp <- palab_tit_res %>%
  anti_join(stopwords_es, by = "palabra") %>%
  anti_join(stopwords_en, by = "palabra") %>%
  anti_join(stopwords_fr, by = "palabra") %>%
  anti_join(stopwords_it, by = "palabra") %>%
  anti_join(stopwords_pt, by = "palabra") %>%
  anti_join(stopwords_de, by = "palabra")  
```


## Análisis simples
### Frencuencia de palabras

```{r}
tit_freq <- palab_tit_limp %>%
  count(palabra, sort = TRUE)
tit_freq
```

```{r}
tit_res_freq <- palab_tit_res_limp %>%
  count(palabra, sort = TRUE)
tit_res_freq
```

## Analisis simples

### Tokenización de términos compuestos

En este caso bigramas

#Bigramas de los títulos ordenados por freq
```{r}
bigram_tit <- palab_tit_limp %>%
  mutate(next_word = lead(palabra)) %>%
  filter(!is.na(next_word)) %>%
  mutate(bigram = paste(palabra, next_word, sep = " ")) %>%
  select(bigram) %>%
  count(bigram, sort = TRUE)
bigram_tit
```

Bigramas de los títulos + resumen ordenados por freq
```{r}
bigram_tit_res <- palab_tit_res_limp %>%
  mutate(next_word = lead(palabra)) %>%
  filter(!is.na(next_word)) %>%
  mutate(bigram = paste(palabra, next_word, sep = " ")) %>%
  select(bigram) %>%
  count(bigram, sort = TRUE)
bigram_tit_res
```

## Nubes de palabras

Wordclouds

```{r}
library(wordcloud2) #Instalar antes el paquete Wordcloud2
```

Filtrar palabras con frecuencia mayor a 1 en el títulos:
```{r}
bigram_tit_f <- bigram_tit %>%
  filter(n > 1) 
```

Ahora en Título + resumen
```{r}
bigram_tit_res_f <- bigram_tit_res %>%
  filter(n > 1) 
```

Creación de la nube de palabras de los títulos:
```{r}
wordcloud2(bigram_tit_f, size = 0.7)
```

Ahora de títulos + resumen

```{r}
wordcloud2(bigram_tit_f, size = 0.7)
```

